{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/_cz8x4hj1730r0wn6pht12dr0000gn/T/ipykernel_60730/2336252215.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Users/lixi/miniconda3/envs/naacp_ml/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import NewsSentiment\n",
    "from NewsSentiment import TargetSentimentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       calgary, alberta — some bruins rely on plant-b...\n",
      "1       washington — a senior treasury department empl...\n",
      "2       edwidge danticat spoke at the luncheon to bene...\n",
      "3       istanbul — his killers were waiting when jamal...\n",
      "4       the new england journal of medicine on wednesd...\n",
      "                              ...                        \n",
      "996     the contrasting treatment captured the opposit...\n",
      "997     though the american airlines pilot soon assure...\n",
      "998     after concerns were voiced at a recent neighbo...\n",
      "999     tucked inside the giant federal spending bill ...\n",
      "1000    as sheila mcgovern, chief judge for the county...\n",
      "Name: lede, Length: 1001, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/_cz8x4hj1730r0wn6pht12dr0000gn/T/ipykernel_60730/4102379144.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['lede'].fillna(\"No lede\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy's English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")  \n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('data/sample_1000rows.csv') \n",
    "data['lede'].fillna(\"No lede\", inplace=True)\n",
    "ledes = data['lede'].apply(lambda x: ' '.join(x.split()[:100]))\n",
    "print(ledes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_ledes = [tuple(string.split(' ', 2)) + ('NA',) * (3 - len(string.split(' ', 2))) for string in ledes]\n",
    "# add logic to make sure no splitted part is empty\n",
    "my_ledes = [\n",
    "    tuple(filtered_parts) + ('NA',) * (3 - len(filtered_parts))\n",
    "    for filtered_parts in ([part for part in s.strip().split(' ', 2) if part] for s in ledes)\n",
    "]\n",
    "# print(my_ledes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 43/1001 [00:10<03:44,  4.27batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   6%|▌         | 56/1001 [00:13<03:38,  4.33batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   8%|▊         | 76/1001 [00:18<03:28,  4.45batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   9%|▉         | 92/1001 [00:21<03:36,  4.20batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  11%|█▏        | 113/1001 [00:26<03:31,  4.20batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  14%|█▍        | 139/1001 [00:32<03:23,  4.23batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  15%|█▍        | 148/1001 [00:34<03:17,  4.32batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  15%|█▍        | 149/1001 [00:35<03:24,  4.17batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  16%|█▌        | 159/1001 [00:37<03:21,  4.19batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  18%|█▊        | 177/1001 [00:41<03:14,  4.23batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  18%|█▊        | 183/1001 [00:43<03:04,  4.44batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  19%|█▉        | 191/1001 [00:44<03:05,  4.37batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  20%|█▉        | 199/1001 [00:46<03:05,  4.33batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  21%|██        | 207/1001 [00:48<03:05,  4.28batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  21%|██        | 210/1001 [00:49<03:03,  4.31batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  21%|██        | 212/1001 [00:49<03:09,  4.17batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  22%|██▏       | 224/1001 [00:52<03:02,  4.26batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  23%|██▎       | 228/1001 [00:53<03:15,  3.96batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  23%|██▎       | 233/1001 [00:54<03:01,  4.24batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  24%|██▍       | 239/1001 [00:56<03:06,  4.09batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  24%|██▍       | 243/1001 [00:57<02:56,  4.30batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  24%|██▍       | 244/1001 [00:57<03:05,  4.09batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  25%|██▌       | 255/1001 [01:00<02:49,  4.40batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  26%|██▋       | 263/1001 [01:02<03:02,  4.04batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  27%|██▋       | 273/1001 [01:04<03:04,  3.94batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  27%|██▋       | 274/1001 [01:05<03:06,  3.89batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  27%|██▋       | 275/1001 [01:05<03:06,  3.89batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  28%|██▊       | 277/1001 [01:05<03:06,  3.89batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  29%|██▊       | 287/1001 [01:08<02:46,  4.29batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  30%|██▉       | 298/1001 [01:10<02:49,  4.14batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  30%|███       | 303/1001 [01:12<02:52,  4.05batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  34%|███▍      | 338/1001 [01:20<02:27,  4.50batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  35%|███▍      | 347/1001 [01:22<02:25,  4.48batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  35%|███▌      | 354/1001 [01:24<02:41,  4.02batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  36%|███▌      | 361/1001 [01:25<02:30,  4.26batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  36%|███▋      | 365/1001 [01:26<02:33,  4.14batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  37%|███▋      | 368/1001 [01:27<02:37,  4.02batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  38%|███▊      | 381/1001 [01:30<02:24,  4.29batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  42%|████▏     | 422/1001 [01:40<02:25,  3.99batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  42%|████▏     | 423/1001 [01:40<02:26,  3.96batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  45%|████▌     | 452/1001 [01:47<02:08,  4.26batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  45%|████▌     | 453/1001 [01:47<02:12,  4.15batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  47%|████▋     | 472/1001 [01:51<02:04,  4.25batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  50%|████▉     | 499/1001 [01:58<01:54,  4.38batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  53%|█████▎    | 533/1001 [02:06<01:55,  4.05batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  59%|█████▊    | 587/1001 [02:19<01:34,  4.36batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  81%|████████  | 813/1001 [03:07<00:42,  4.47batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  84%|████████▎ | 837/1001 [03:13<00:35,  4.62batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  88%|████████▊ | 881/1001 [03:22<00:27,  4.33batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  88%|████████▊ | 884/1001 [03:23<00:26,  4.40batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:  92%|█████████▏| 923/1001 [03:31<00:16,  4.72batch/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches: 100%|██████████| 1001/1001 [03:49<00:00,  4.37batch/s]\n"
     ]
    }
   ],
   "source": [
    "tsc = TargetSentimentClassifier()\n",
    "sentiments = tsc.infer(targets=my_ledes)\n",
    "\n",
    "res = []\n",
    "for i, result in enumerate(sentiments):\n",
    "    res.append(result[0]['class_label'])\n",
    "    # print(\"Sentiment: \", result[0]['class_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['roberta_sentiment_basedOnLedes'] = res\n",
    "data.to_csv('data/sample_1000rows_Roberta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract entities\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract entities context\n",
    "def extract_entities_with_context(text, window=5):\n",
    "    doc = nlp(text)\n",
    "    entity_context = []\n",
    "    for ent in doc.ents:\n",
    "        start = max(0, ent.start - window)\n",
    "        end = min(len(doc), ent.end + window)\n",
    "        context = doc[start:end].text\n",
    "        entity_context.append((ent.text, ent.label_, context))\n",
    "    return entity_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['entities'] = ledes.apply(extract_entities)\n",
    "data['entity_context'] = ledes.apply(extract_entities_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    tsc = TargetSentimentClassifier()\n",
    "    sentiments = tsc.infer(targets=text)\n",
    "\n",
    "    res = []\n",
    "    for i, result in enumerate(sentiments):\n",
    "        res.append(result[0]['class_label'])\n",
    "        # print(\"Sentiment: \", result[0]['class_label'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze sentiment around each entity\n",
    "def analyze_entity_sentiments(entity_contexts):\n",
    "    sentiments = []\n",
    "    for text, label, context in entity_contexts:\n",
    "        sentiment = get_sentiment(context)\n",
    "        sentiments.append((text, label, sentiment))\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just store sentiment score\n",
    "def analyze_entity_sentiments_score(entity_contexts):\n",
    "    sentiments = []\n",
    "    for text, label, context in entity_contexts:\n",
    "        sentiment = get_sentiment(context)\n",
    "        sentiments.append((sentiment))\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentiment score\n",
    "data['entity_sentiments_scoreonly'] = data['entity_context'].apply(analyze_entity_sentiments_score)\n",
    "data['most_negative_score'] = data['entity_sentiments_scoreonly'].apply(lambda x: min(x) if x else float('inf'))\n",
    "data['most_positive_score'] = data['entity_sentiments_scoreonly'].apply(lambda x: max(x) if x else float('inf'))\n",
    "data['average_score'] = data['entity_sentiments_scoreonly'].apply(lambda x: sum(x) / len(x) if x else float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_sentiment(score):\n",
    "    if score <= -0.1:\n",
    "        return 'Negative'\n",
    "    elif score >= 0.1:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['most_negative_sentiment'] = data['most_negative_score'].apply(categorize_sentiment)\n",
    "data['most_positive_sentiment'] = data['most_positive_score'].apply(categorize_sentiment)\n",
    "data['average_sentiment'] = data['average_score'].apply(categorize_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Apply the function to each lede\n",
    "# print(data.head())\n",
    "data.to_csv('data/sample_1000rows_spacy_roberta.csv') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naacp_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
